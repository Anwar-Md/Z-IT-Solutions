{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-4: Natural Language Processing (NLP) Basics:\n",
    "### Write a Python script using NLTK or spaCy to perform basic text processing tasks like tokenization, stemming, or sentiment analysis on a sample       text.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries :\n",
    "First, we import the necessary libraries from NLTK for performing various NLP tasks. These include tokenization, stemming, and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Necessary NLTK Data Files :\n",
    "We need to download some necessary data files from NLTK for tokenization and sentiment analysis. This includes the 'punkt' tokenizer models and the 'vader_lexicon' for sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Anwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Text :\n",
    "We define a sample text to perform our NLP tasks. This text will be tokenized, stemmed, and analyzed for sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural Language Processing is an exciting field. It helps in understanding and analyzing human language.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization :\n",
    "Tokenization is the process of breaking down text into smaller units, such as words or sentences. Here, we use 'word_tokenize' to tokenize the text into words and 'sent_tokenize' to tokenize it into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokenization: ['Natural', 'Language', 'Processing', 'is', 'an', 'exciting', 'field', '.', 'It', 'helps', 'in', 'understanding', 'and', 'analyzing', 'human', 'language', '.']\n",
      "Sentence Tokenization: ['Natural Language Processing is an exciting field.', 'It helps in understanding and analyzing human language.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(text)\n",
    "print(\"Word Tokenization:\", words)\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentence Tokenization:\", sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming :\n",
    "Stemming is the process of reducing words to their base or root form. We use the PorterStemmer from NLTK to stem the tokenized words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Words: ['natur', 'languag', 'process', 'is', 'an', 'excit', 'field', '.', 'it', 'help', 'in', 'understand', 'and', 'analyz', 'human', 'languag', '.']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stemmed_words = [ps.stem(word) for word in words]\n",
    "print(\"Stemmed Words:\", stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis :\n",
    "Sentiment analysis involves determining the emotional tone of the text. We use the VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analysis tool from NLTK to analyze the sentiment of the sample text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis: {'neg': 0.0, 'neu': 0.591, 'pos': 0.409, 'compound': 0.8074}\n"
     ]
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "sentiment = sid.polarity_scores(text)\n",
    "print(\"Sentiment Analysis:\", sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion :\n",
    "### In this project, I successfully implemented basic text processing tasks using NLTK. I performed tokenization to break the text into words and sentences, applied stemming to reduce words to their root forms, and conducted sentiment analysis to determine the emotional tone of the text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
